{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "from argparse import ArgumentParser\n",
    "from pathlib import Path\n",
    "\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "txt_files = sorted(Path(\"./datasets\").glob(\"*.txt\"))\n",
    "f = open(\"./content/words.txt\", \"w\", encoding=\"utf-8\")\n",
    "for txt_file in txt_files:\n",
    "    wav_file = txt_file.with_suffix(\".wav\")\n",
    "    if not wav_file.exists():\n",
    "        continue\n",
    "    line = open(txt_file, \"r\", encoding=\"utf-8\").read()\n",
    "    for word in line.strip().lower().split():\n",
    "        f.write(word)\n",
    "        f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "black_list = (\n",
    "    []\n",
    "    + [\"q\", \"adn\", \"h\", \"stress\", \"b\", \"k\", \"mark\", \"gas\", \"cs\", \"test\", \"l\", \"hiv\"]\n",
    "    + [\"v\", \"d\", \"c\", \"p\", \"martin\", \"visa\", \"euro\", \"laser\", \"x\", \"real\", \"shop\"]\n",
    "    + [\"studio\", \"kelvin\", \"đt\", \"pop\", \"rock\", \"gara\", \"karaoke\", \"đicr\", \"đigiúp\"]\n",
    "    + [\"khmer\", \"ii\", \"s\", \"tr\", \"xhcn\", \"casino\", \"guitar\", \"sex\", \"oxi\", \"radio\"]\n",
    "    + [\"qúy\", \"asean\", \"hlv\" \"ts\", \"video\", \"virus\", \"usd\", \"robot\", \"ph\", \"album\"]\n",
    "    + [\"s\", \"kg\", \"km\", \"g\", \"tr\", \"đ\", \"ak\", \"d\", \"m\", \"n\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = open(\"./content/words.txt\").readlines()\n",
    "f = open(\"./content/lexicon.txt\", \"w\")\n",
    "for w in sorted(set(ws)):\n",
    "    w = w.strip()\n",
    "\n",
    "    # this is a hack to match phoneme set in the vietTTS repo\n",
    "    p = list(w)\n",
    "    p = \" \".join(p)\n",
    "    if w in black_list:\n",
    "        continue\n",
    "    else:\n",
    "        f.write(f\"{w}\\t{p}\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('datasets/00000.txt')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vntts.hifigan.mel2wave import mel2wave\n",
    "from vntts.nat.config import FLAGS\n",
    "from vntts.nat.text2mel import text2mel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('/home/nguyen/Desktop/vietTTS/vntts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nat_normalize_text(text):\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    text = text.lower().strip()\n",
    "    sil = FLAGS.special_phonemes[FLAGS.sil_index]\n",
    "    text = re.sub(r\"[\\n.,:]+\", f\" {sil} \", text)\n",
    "    text = text.replace('\"', \" \")\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"[.,:;?!]+\", f\" {sil} \", text)\n",
    "    text = re.sub(\"[ ]+\", \" \", text)\n",
    "    text = re.sub(f\"( {sil}+)+ \", f\" {sil} \", text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nat_normalize_text(\"Xin chào các bạn\")\n",
    "output = Path(\"clip.wav\")\n",
    "sample_rate = 16000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_file = \"/home/nguyen/Desktop/vietTTS/tts-lab/lexicon.txt\"\n",
    "silence_duration =  -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vntts as vntts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized text input: xin chào các bạn\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'assets/infore/hifigan/hk_hifi.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/nguyen/Desktop/vietTTS/notes.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nguyen/Desktop/vietTTS/notes.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNormalized text input:\u001b[39m\u001b[39m\"\u001b[39m, text)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nguyen/Desktop/vietTTS/notes.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mel \u001b[39m=\u001b[39m text2mel(text, lexicon_file,silence_duration)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nguyen/Desktop/vietTTS/notes.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m wave \u001b[39m=\u001b[39m mel2wave(mel)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nguyen/Desktop/vietTTS/notes.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mwriting output to file\u001b[39m\u001b[39m\"\u001b[39m, output)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nguyen/Desktop/vietTTS/notes.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m sf\u001b[39m.\u001b[39mwrite(\u001b[39mstr\u001b[39m(output), wave, samplerate\u001b[39m=\u001b[39msample_rate)\n",
      "File \u001b[0;32m~/Desktop/vietTTS/vntts/hifigan/mel2wave.py:35\u001b[0m, in \u001b[0;36mmel2wave\u001b[0;34m(mel)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39mreturn\u001b[39;00m net(x)\n\u001b[1;32m     33\u001b[0m rng \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(hk\u001b[39m.\u001b[39mPRNGSequence(\u001b[39m42\u001b[39m))\n\u001b[0;32m---> 35\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(FLAGS\u001b[39m.\u001b[39;49mckpt_dir \u001b[39m/\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mhk_hifi.pickle\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     36\u001b[0m     params \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m     37\u001b[0m aux \u001b[39m=\u001b[39m {}\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'assets/infore/hifigan/hk_hifi.pickle'"
     ]
    }
   ],
   "source": [
    "print(\"Normalized text input:\", text)\n",
    "mel = text2mel(text, lexicon_file,silence_duration)\n",
    "wave = mel2wave(mel)\n",
    "print(\"writing output to file\", output)\n",
    "sf.write(str(output), wave, samplerate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[[-11.523805 , -11.507941 , -11.511615 , ..., -11.500495 ,\n",
       "               -11.510264 , -11.503636 ],\n",
       "              [-11.592315 , -11.607649 , -11.591606 , ..., -11.594408 ,\n",
       "               -11.5748825, -11.607619 ],\n",
       "              [-11.566815 , -11.588497 , -11.588512 , ..., -11.566287 ,\n",
       "               -11.573196 , -11.5953045],\n",
       "              ...,\n",
       "              [ -8.12596  ,  -7.5511985,  -7.2342   , ..., -10.777324 ,\n",
       "               -10.773255 , -10.9984455],\n",
       "              [ -8.184135 ,  -7.6728964,  -7.436137 , ..., -10.91444  ,\n",
       "               -10.8881   , -11.02587  ],\n",
       "              [ -8.461478 ,  -8.136272 ,  -7.8908567, ..., -11.1447525,\n",
       "               -11.19443  , -11.175263 ]]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2mel(text, lexicon_file,silence_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel = text2mel(text, lexicon_file,silence_duration)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(mel[0].T, origin=\"lower\", aspect=\"auto\")\n",
    "plt.savefig(\"mel.png\")\n",
    "plt.close()\n",
    "mel = jax.device_get(mel)\n",
    "mel.tofile(\"clip.mel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nguyen/Desktop/vietTTS'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fish: Unknown command: mfa\n",
      "fish: \n",
      "mfa train --clean -t ./temp -o ./infore_mfa.zip ./infore_16k_denoised lexicon.txt ./infore_textgrid\n",
      "^\n"
     ]
    }
   ],
   "source": [
    "!mfa train --clean -t ./temp -o ./infore_mfa.zip ./infore_16k_denoised lexicon.txt ./infore_textgrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train duration model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-26 22:58:15.993807: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-26 22:58:16.020692: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-26 22:58:16.022490: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "/home/nguyen/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading latest checkpoint from file assets/infore/nat/duration_latest_ckpt.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  35%|███████████▉                      | 70001/200001 [00:00<?, ?it/s]2022-10-26 22:58:57.028756: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:401] There was an error before creating cudnn handle: cudaGetErrorName symbol not found. : cudaGetErrorString symbol not found.\n",
      "2022-10-26 22:58:57.037293: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-26 22:58:57.037318: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-10-26 22:58:57.037363: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:401] There was an error before creating cudnn handle: cudaGetErrorName symbol not found. : cudaGetErrorString symbol not found.\n",
      "2022-10-26 22:58:57.037370: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-10-26 22:58:57.037396: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:401] There was an error before creating cudnn handle: cudaGetErrorName symbol not found. : cudaGetErrorString symbol not found.\n",
      "2022-10-26 22:58:57.037403: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-10-26 22:58:57.037548: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:401] There was an error before creating cudnn handle: cudaGetErrorName symbol not found. : cudaGetErrorString symbol not found.\n",
      "2022-10-26 22:58:57.037554: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-10-26 22:58:57.037585: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:401] There was an error before creating cudnn handle: cudaGetErrorName symbol not found. : cudaGetErrorString symbol not found.\n",
      "2022-10-26 22:58:57.037591: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-10-26 22:58:57.037637: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:401] There was an error before creating cudnn handle: cudaGetErrorName symbol not found. : cudaGetErrorString symbol not found.\n",
      "2022-10-26 22:58:57.037642: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-10-26 22:58:57.037655: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:401] There was an error before creating cudnn handle: cudaGetErrorName symbol not found. : cudaGetErrorString symbol not found.\n",
      "2022-10-26 22:58:57.037661: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-10-26 22:58:57.037681: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:401] There was an error before creating cudnn handle: cudaGetErrorName symbol not found. : cudaGetErrorString symbol not found.\n",
      "2022-10-26 22:58:57.037686: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-10-26 22:58:57.037696: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:401] There was an error before creating cudnn handle: cudaGetErrorName symbol not found. : cudaGetErrorString symbol not found.\n",
      "2022-10-26 22:58:57.037703: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-10-26 22:58:57.305319: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-26 22:58:57.305353: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:219] failed to create cublas handle: cublas error\n",
      "2022-10-26 22:58:57.305367: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:401] There was an error before creating cudnn handle: cudaGetErrorName symbol not found. : cudaGetErrorString symbol not found.\n",
      "2022-10-26 22:58:57.305372: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "2022-10-26 22:58:57.305789: W external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:401] There was an error before creating cudnn handle: cudaGetErrorName symbol not found. : cudaGetErrorString symbol not found.\n",
      "2022-10-26 22:58:57.305803: E external/org_tensorflow/tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:433] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "training:  35%|███████████▉                      | 70001/200001 [00:40<?, ?it/s]\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bw-filter = (f32[3,256,256]{0,1,2}, u8[0]{0}) custom-call(f32[64,256,256]{1,2,0} %multiply.18, f32[64,256,256]{1,2,0} %add.1759), window={size=3 pad=1_1}, dim_labels=b0f_0io->b0f, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_name=\"jit(update)/jit(main)/transpose(jvp(duration_model))/token_encoder/conv1_d_2/conv_general_dilated[window_strides=(1,) padding=((1, 1),) lhs_dilation=(1,) rhs_dilation=(1,) dimension_numbers=ConvDimensionNumbers(lhs_spec=(2, 0, 1), rhs_spec=(2, 0, 1), out_spec=(1, 2, 0)) feature_group_count=1 batch_group_count=1 lhs_shape=(64, 256, 256) rhs_shape=(64, 256, 256) precision=None preferred_element_type=None]\" source_file=\"/home/nguyen/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/haiku/_src/conv.py\" source_line=205}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nOriginal error: UNIMPLEMENTED: DNN library is not found.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/media/nguyen/01D8DBC4BA83C360/ptit/vietTTS/notes.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/nguyen/01D8DBC4BA83C360/ptit/vietTTS/notes.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mvntts\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mduration_trainer\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mduration_trainer\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/nguyen/01D8DBC4BA83C360/ptit/vietTTS/notes.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m duration_trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/media/nguyen/01D8DBC4BA83C360/ptit/vietTTS/vntts/nat/duration_trainer.py:118\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m tr:\n\u001b[1;32m    117\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(train_data_iter)\n\u001b[0;32m--> 118\u001b[0m     loss, (params, aux, rng, optim_state) \u001b[39m=\u001b[39m update(\n\u001b[1;32m    119\u001b[0m         params, aux, rng, optim_state, batch\n\u001b[1;32m    120\u001b[0m     )\n\u001b[1;32m    121\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m    123\u001b[0m     \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m \u001b[39m10\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/jax/_src/dispatch.py:994\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, built_c, options, host_callbacks)\u001b[0m\n\u001b[1;32m    989\u001b[0m   \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mcompile(built_c, compile_options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    990\u001b[0m                          host_callbacks\u001b[39m=\u001b[39mhost_callbacks)\n\u001b[1;32m    991\u001b[0m \u001b[39m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \u001b[39m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[39m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 994\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcompile(built_c, compile_options\u001b[39m=\u001b[39;49moptions)\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: UNKNOWN: Failed to determine best cudnn convolution algorithm for:\n%cudnn-conv-bw-filter = (f32[3,256,256]{0,1,2}, u8[0]{0}) custom-call(f32[64,256,256]{1,2,0} %multiply.18, f32[64,256,256]{1,2,0} %add.1759), window={size=3 pad=1_1}, dim_labels=b0f_0io->b0f, custom_call_target=\"__cudnn$convBackwardFilter\", metadata={op_name=\"jit(update)/jit(main)/transpose(jvp(duration_model))/token_encoder/conv1_d_2/conv_general_dilated[window_strides=(1,) padding=((1, 1),) lhs_dilation=(1,) rhs_dilation=(1,) dimension_numbers=ConvDimensionNumbers(lhs_spec=(2, 0, 1), rhs_spec=(2, 0, 1), out_spec=(1, 2, 0)) feature_group_count=1 batch_group_count=1 lhs_shape=(64, 256, 256) rhs_shape=(64, 256, 256) precision=None preferred_element_type=None]\" source_file=\"/home/nguyen/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/haiku/_src/conv.py\" source_line=205}, backend_config=\"{\\\"conv_result_scale\\\":1,\\\"activation_mode\\\":\\\"0\\\",\\\"side_input_scale\\\":0}\"\n\nOriginal error: UNIMPLEMENTED: DNN library is not found.\n\nTo ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning."
     ]
    }
   ],
   "source": [
    "import vntts.nat.duration_trainer as duration_trainer\n",
    "duration_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train acoustic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/media/nguyen/01D8DBC4BA83C360/ptit/vietTTS/notes.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/nguyen/01D8DBC4BA83C360/ptit/vietTTS/notes.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mvntts\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39macoustic_trainer\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39macoustic_trainer\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/media/nguyen/01D8DBC4BA83C360/ptit/vietTTS/notes.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m acoustic_trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/media/nguyen/01D8DBC4BA83C360/ptit/vietTTS/vntts/nat/acoustic_trainer.py:117\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m val_data_iter \u001b[39m=\u001b[39m load_textgrid_wav(\n\u001b[1;32m    108\u001b[0m     FLAGS\u001b[39m.\u001b[39mdata_dir,\n\u001b[1;32m    109\u001b[0m     FLAGS\u001b[39m.\u001b[39mmax_phoneme_seq_len,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    113\u001b[0m )\n\u001b[1;32m    114\u001b[0m melfilter \u001b[39m=\u001b[39m MelFilter(\n\u001b[1;32m    115\u001b[0m     FLAGS\u001b[39m.\u001b[39msample_rate, FLAGS\u001b[39m.\u001b[39mn_fft, FLAGS\u001b[39m.\u001b[39mmel_dim, FLAGS\u001b[39m.\u001b[39mfmin, FLAGS\u001b[39m.\u001b[39mfmax\n\u001b[1;32m    116\u001b[0m )\n\u001b[0;32m--> 117\u001b[0m batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(train_data_iter)\n\u001b[1;32m    118\u001b[0m batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39m_replace(mels\u001b[39m=\u001b[39mmelfilter(batch\u001b[39m.\u001b[39mwavs\u001b[39m.\u001b[39mastype(jnp\u001b[39m.\u001b[39mfloat32) \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m15\u001b[39m)))\n\u001b[1;32m    119\u001b[0m params, aux, rng, optim_state \u001b[39m=\u001b[39m initial_state(optimizer, batch)\n",
      "File \u001b[0;32m/media/nguyen/01D8DBC4BA83C360/ptit/vietTTS/vntts/nat/data_loader.py:103\u001b[0m, in \u001b[0;36mload_textgrid_wav\u001b[0;34m(data_dir, token_seq_len, batch_size, pad_wav_len, mode)\u001b[0m\n\u001b[1;32m    101\u001b[0m data \u001b[39m=\u001b[39m []\n\u001b[1;32m    102\u001b[0m \u001b[39mfor\u001b[39;00m fn \u001b[39min\u001b[39;00m tg_files:\n\u001b[0;32m--> 103\u001b[0m     ps, ds \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mload_textgrid(fn))\n\u001b[1;32m    104\u001b[0m     ps \u001b[39m=\u001b[39m [phonemes\u001b[39m.\u001b[39mindex(p) \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m ps]\n\u001b[1;32m    105\u001b[0m     l \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(ps)\n",
      "File \u001b[0;32m/media/nguyen/01D8DBC4BA83C360/ptit/vietTTS/vntts/nat/data_loader.py:30\u001b[0m, in \u001b[0;36mload_textgrid\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_textgrid\u001b[39m(fn: Path):\n\u001b[1;32m     29\u001b[0m     \u001b[39m\"\"\"load textgrid file\"\"\"\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m     tg \u001b[39m=\u001b[39m textgrid\u001b[39m.\u001b[39;49mTextGrid\u001b[39m.\u001b[39;49mfromFile(\u001b[39mstr\u001b[39;49m(fn\u001b[39m.\u001b[39;49mresolve()))\n\u001b[1;32m     31\u001b[0m     data \u001b[39m=\u001b[39m []\n\u001b[1;32m     32\u001b[0m     words \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(tg[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/textgrid/textgrid.py:807\u001b[0m, in \u001b[0;36mTextGrid.fromFile\u001b[0;34m(cls, f, name)\u001b[0m\n\u001b[1;32m    804\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    805\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfromFile\u001b[39m(\u001b[39mcls\u001b[39m, f, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    806\u001b[0m     tg \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(name\u001b[39m=\u001b[39mname)\n\u001b[0;32m--> 807\u001b[0m     tg\u001b[39m.\u001b[39;49mread(f)\n\u001b[1;32m    808\u001b[0m     \u001b[39mreturn\u001b[39;00m tg\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/textgrid/textgrid.py:736\u001b[0m, in \u001b[0;36mTextGrid.read\u001b[0;34m(self, f, round_digits, encoding)\u001b[0m\n\u001b[1;32m    734\u001b[0m         jmrk \u001b[39m=\u001b[39m _getMark(source, short)\n\u001b[1;32m    735\u001b[0m         \u001b[39mif\u001b[39;00m jmin \u001b[39m<\u001b[39m jmax:  \u001b[39m# non-null\u001b[39;00m\n\u001b[0;32m--> 736\u001b[0m             itie\u001b[39m.\u001b[39;49maddInterval(Interval(jmin, jmax, jmrk))\n\u001b[1;32m    737\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mappend(itie)\n\u001b[1;32m    738\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# pointTier\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/textgrid/textgrid.py:459\u001b[0m, in \u001b[0;36mIntervalTier.addInterval\u001b[0;34m(self, interval)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maddInterval\u001b[39m(\u001b[39mself\u001b[39m, interval):\n\u001b[0;32m--> 459\u001b[0m     \u001b[39mif\u001b[39;00m interval\u001b[39m.\u001b[39mminTime \u001b[39m<\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mminTime:  \u001b[39m# too early\u001b[39;00m\n\u001b[1;32m    460\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mminTime)\n\u001b[1;32m    461\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxTime \u001b[39mand\u001b[39;00m interval\u001b[39m.\u001b[39mmaxTime \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxTime:  \u001b[39m# too late\u001b[39;00m\n\u001b[1;32m    462\u001b[0m         \u001b[39m# raise ValueError, self.maxTime\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import vntts.nat.acoustic_trainer as acoustic_trainer\n",
    "acoustic_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HiFiGAN vocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py \\\n",
    "  --config ../assets/hifigan/config.json \\\n",
    "  --input_wavs_dir=data \\\n",
    "  --input_training_file=train_files.txt \\\n",
    "  --input_validation_file=val_files.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uvicorn main:app --host 0.0.0.0 --port 8000 --reload"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c0bbc9c5607dc4ca787e7917777e4e66882ef8eb9e6a4a68c31af35018f6555"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
